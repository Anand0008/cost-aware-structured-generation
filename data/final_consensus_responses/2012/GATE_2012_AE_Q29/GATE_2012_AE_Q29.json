{
  "question_id": "GATE_2012_AE_Q29",
  "exam_name": "GATE",
  "subject": "Aerospace Engineering",
  "year": 2012,
  "question_number": 29,
  "question_text": "A rocket motor has combustion chamber temperature of 2600 K and the products have molecular weight of 25 g/mol and ratio of specific heats 1.2. The universal gas constant is 8314 J/kg-mole-K. The value of theoretical c* (in m/s) is ____.",
  "question_text_latex": "T_c=2600 \\text{ K}, MW=25 \\text{ g/mol}, \\gamma=1.2, R_u=8314 \\text{ J/kg-mole-K}",
  "question_type": "NAT",
  "marks": 2.0,
  "negative_marks": 0.0,
  "options": null,
  "answer_key": "1430 to 1440",
  "has_question_image": false,
  "image_metadata": null,
  "tier_0_classification": {
    "content_type": "numerical_calculation",
    "media_type": "text_only",
    "difficulty_score": 4,
    "complexity_flags": {
      "requires_derivation": false,
      "multi_concept_integration": false,
      "ambiguous_wording": false,
      "image_interpretation_complex": false,
      "edge_case_scenario": false,
      "multi_step_reasoning": false,
      "approximation_needed": false
    },
    "use_gpt51": false,
    "classification_confidence": 0.95,
    "classification_reasoning": "This question requires a straightforward numerical calculation using the formula for characteristic velocity (c*). It involves plugging in given values and performing the computation. The difficulty is relatively low as it's a direct application of a formula.",
    "combined_type": "numerical_calculation_text_only",
    "weight_strategy": "NUMERICAL_WEIGHTED",
    "classification_method": "llm_assisted",
    "classifier_model": "gemini_2.0_flash_exp"
  },
  "tier_1_core_research": {
    "explanation": null,
    "step_by_step_solution": null,
    "answer_validation": null,
    "hierarchical_tags": null,
    "prerequisites": null,
    "textbook_references": null,
    "video_references": null,
    "real_world_applications": null,
    "formulas_principles": null,
    "difficulty_analysis": null
  },
  "tier_2_student_learning": {
    "flashcards": null,
    "exam_strategy": null,
    "common_mistakes": null,
    "mnemonics_memory_aids": null,
    "real_world_context": null
  },
  "tier_3_enhanced_learning": {
    "connections_to_other_subjects": null,
    "deeper_dive_topics": null,
    "alternative_methods": null,
    "search_keywords": null
  },
  "tier_4_metadata_and_future": {
    "model_meta": {
      "models_used": [
        "claude_sonnet_4.5",
        "gemini_2.5_pro",
        "deepseek_r1"
      ],
      "model_count": 3,
      "weight_strategy": "NUMERICAL_WEIGHTED",
      "weights_applied": {
        "gemini_2.5_pro": 0.25,
        "claude_sonnet_4.5": 0.25,
        "deepseek_r1": 0.5
      },
      "consensus_method": "weighted_voting",
      "debate_rounds": 2,
      "converged_fields_count": 0,
      "debated_fields_count": 1,
      "flagged_for_review": [
        "RED_LINE_FAILURE"
      ],
      "gpt51_added_in_debate": true,
      "timestamp": "2025-12-20T15:55:16.398290",
      "pipeline_version": "1.0.0"
    },
    "quality_score": {
      "overall": 0.671,
      "band": "REVIEW",
      "metrics": {
        "avg_model_confidence": 0.75,
        "consensus_rate": 0.9,
        "debate_efficiency": 0.7,
        "rag_relevance": 0.489,
        "field_completeness": 0.0
      }
    },
    "cost_breakdown": {
      "total_cost": 0.15123431999999998,
      "currency": "USD",
      "per_model": {
        "claude_sonnet_4.5": 0.091239,
        "gemini_2.5_pro": 0.00428445,
        "deepseek_r1": 0.02107179
      },
      "classification_cost": 5e-05,
      "image_consensus_cost": 0,
      "debate_cost": 0.03463908,
      "total_api_calls": 9
    },
    "token_usage": {
      "total_input_tokens": 30529,
      "total_output_tokens": 15744,
      "total_tokens": 46273,
      "per_model": {
        "claude_sonnet_4.5": {
          "input": 10838,
          "output": 3915,
          "total": 14753
        },
        "gemini_2.5_pro": {
          "input": 10211,
          "output": 4588,
          "total": 14799
        },
        "deepseek_r1": {
          "input": 9480,
          "output": 7241,
          "total": 16721
        }
      }
    },
    "processing_time": {
      "total_seconds": 406.30809688568115,
      "per_stage": {
        "stage_1": 0.002010345458984375,
        "stage_2": 2.0904457569122314,
        "stage_3": 1.6491403579711914,
        "stage_4": 38.33485651016235,
        "stage_5": 223.79354047775269,
        "stage_6": 0.008342742919921875,
        "stage_7": 140.42976069450378,
        "stage_8": 0.002378225326538086
      },
      "bottleneck_stage": "stage_5",
      "parallel_generation_time": 223.79354047775269,
      "debate_time": 140.42976069450378
    }
  }
}