# FLSS Ablation Analysis Report

**Generated:** 2026-01-12T11:32:09.872764
**Questions Analyzed:** 1268
**Models:** claude_sonnet_4.5, deepseek_r1, gemini_2.5_pro, gpt_5_1

---

## Executive Summary

This analysis compares the Field-Level Structural Synthesis (FLSS) consensus outputs
against single-model baselines to quantify the value of multi-LLM consensus.

---

## 1. Field Completeness

| Method | Mean | Median | Std Dev |
|--------|------|--------|---------|
| **FLSS Consensus** | 99.76% | 100.00% | 0.73% |
| Best-of-N | 99.07% | 100.00% | 1.52% |
| claude_sonnet_4.5 | 99.20% | 100.00% | 1.21% |
| deepseek_r1 | 99.51% | 100.00% | 0.99% |
| gemini_2.5_pro | 98.54% | 98.90% | 1.86% |
| gpt_5_1 | 99.99% | 100.00% | 0.13% |

---

## 2. Pedagogical Content Richness

### 2.1 Mnemonic Count

| Method | Mean | Median | Max |
|--------|------|--------|-----|
| **FLSS Consensus** | 1.96 | 2.0 | 5 |
| Best-of-N | 1.14 | 1.0 | 3 |
| claude_sonnet_4.5 | 1.00 | 1.0 | 2 |
| deepseek_r1 | 1.60 | 2.0 | 3 |
| gemini_2.5_pro | 0.69 | 1.0 | 3 |
| gpt_5_1 | 1.77 | 2.0 | 3 |

### 2.2 Flashcard Count

| Method | Mean | Median | Max |
|--------|------|--------|-----|
| **FLSS Consensus** | 4.60 | 5.0 | 6 |
| Best-of-N | 4.07 | 4.0 | 6 |
| claude_sonnet_4.5 | 2.90 | 3.0 | 6 |
| deepseek_r1 | 4.32 | 4.0 | 6 |
| gemini_2.5_pro | 3.83 | 4.0 | 6 |
| gpt_5_1 | 4.79 | 5.0 | 6 |

### 2.3 Common Mistakes Identified

| Method | Mean | Median | Max |
|--------|------|--------|-----|
| **FLSS Consensus** | 3.57 | 4.0 | 5 |
| Best-of-N | 3.13 | 3.0 | 5 |
| claude_sonnet_4.5 | 2.43 | 2.0 | 3 |
| deepseek_r1 | 3.48 | 3.0 | 5 |
| gemini_2.5_pro | 2.81 | 3.0 | 4 |
| gpt_5_1 | 3.58 | 4.0 | 5 |

---

## 3. Total Array Items (All Pedagogical Content)

| Method | Mean | Median | Std Dev |
|--------|------|--------|---------|
| **FLSS Consensus** | 55.8 | 56.0 | 6.7 |
| Best-of-N | 46.7 | 48.0 | 7.9 |
| claude_sonnet_4.5 | 34.6 | 35.0 | 6.6 |
| deepseek_r1 | 49.0 | 50.0 | 6.6 |
| gemini_2.5_pro | 44.2 | 46.0 | 9.7 |
| gpt_5_1 | 54.7 | 55.0 | 5.1 |

---

## 4. FLSS Improvement Over Best-of-N

| Metric | Improvement |
|--------|-------------|
| classification_confidence | 0.0% |
| common_mistakes_count | +14.0% |
| confidence | -3.5% |
| field_completeness | +0.7% |
| flashcard_count | +12.9% |
| formulas_count | +27.0% |
| mnemonic_count | +72.4% |
| non_null_fields | +11.9% |
| score | +15.9% |
| step_count | +12.2% |
| total_array_items | +19.5% |
| total_fields | +11.1% |
| total_text_length | +32.6% |

---

## Methodology

- **FLSS Consensus**: Final merged output from the voting engine
- **Best-of-N**: Single model response with highest answer confidence
- **Individual Models**: Raw outputs from each model before consensus

### Metrics Explained

- **Field Completeness**: Percentage of schema fields with non-null values
- **Mnemonic Count**: Number of memory aids generated
- **Flashcard Count**: Number of study flashcards created
- **Common Mistakes**: Student error patterns identified
- **Total Array Items**: Sum of all pedagogical list items

---

*Generated by `ablation_analysis.py`*